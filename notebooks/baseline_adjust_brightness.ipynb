{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    " ## Cloud Cover Semantic Segmentation\n",
    "### Final project: Baseline\n",
    "\n",
    "Project Team: <br>\n",
    "Kurt Eulau <br>\n",
    "Steve Hewitt <br>\n",
    "Tom Welsh <br>\n",
    "\n",
    "\n",
    "Citations: <br>\n",
    " - TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives: \n",
    " - TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Import packages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas_path pytorch_lightning cloudpathlib loguru typer\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_path import path  # noqa\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import rasterio\n",
    "import pyproj\n",
    "import rioxarray\n",
    "import xrspatial.multispectral as ms\n",
    "from my_preprocessing import train_val_test_split\n",
    "import segmentation_models_pytorch as smp\n",
    "from typing import Optional, List\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1A (Optional): Log training to wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"baseline-adjust-brightness\", entity=\"w207-clouds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Define working directories and global variables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/driven-data/cloud-cover\")\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "assert TRAIN_FEATURES.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = [\"B02\", \"B03\", \"B04\", \"B08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = pd.read_csv(DATA_DIR / \"train_metadata.csv\")\n",
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create benchmark_src folder\n",
    "submission_dir = Path(\"benchmark_src\")\n",
    "if submission_dir.exists():\n",
    "    shutil.rmtree(submission_dir)\n",
    "\n",
    "submission_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Create scripts to define loss function and classes.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file {submission_dir}/losses.py\n",
    "import numpy as np\n",
    "\n",
    "def intersection_over_union(pred, true):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates intersection and union for a batch of images.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): a tensor of predictions\n",
    "        true (torc.Tensor): a tensor of labels\n",
    "\n",
    "    Returns:\n",
    "        intersection (int): total intersection of pixels\n",
    "        union (int): total union of pixels\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    valid_pixel_mask = true.ne(255)  # valid pixel mask\n",
    "    true = true.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "    pred = pred.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "\n",
    "    # Intersection and union totals\n",
    "    intersection = np.logical_and(true, pred)\n",
    "    union = np.logical_or(true, pred)\n",
    "    return intersection.sum() / union.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file {submission_dir}/cloud_dataset.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "from typing import Optional, List\n",
    "\n",
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Reads in images, transforms pixel values, and serves a\n",
    "    dictionary containing chip ids, image tensors, and\n",
    "    label masks (where available).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_paths: pd.DataFrame, # : syntax specifies datatype for each parameter for CloudDataset objects\n",
    "        bands: List[str],\n",
    "        y_paths: Optional[pd.DataFrame] = None,\n",
    "        transforms: Optional[list] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiate the CloudDataset class.\n",
    "\n",
    "        Args:\n",
    "            x_paths (pd.DataFrame): a dataframe with a row for each chip. There must be a column for chip_id,\n",
    "                and a column with the path to the TIF for each of bands\n",
    "            bands (list[str]): list of the bands included in the data\n",
    "            y_paths (pd.DataFrame, optional): a dataframe with a for each chip and columns for chip_id\n",
    "                and the path to the label TIF with ground truth cloud cover\n",
    "            transforms (list, optional): list of transforms to apply to the feature data (eg augmentations)\n",
    "        \"\"\"\n",
    "        self.data = x_paths\n",
    "        self.label = y_paths\n",
    "        self.transforms = transforms\n",
    "        self.bands = bands\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # Similar to pop, helps iterate through dataset\n",
    "    def __getitem__(self, idx: int):\n",
    "        # Loads an n-channel image from a chip-level dataframe\n",
    "        img = self.data.loc[idx]\n",
    "        band_arrs = []\n",
    "        for band in self.bands:\n",
    "            with rasterio.open(img[f\"{band}_path\"]) as b:\n",
    "                band_arr = b.read(1).astype(\"float32\")\n",
    "            band_arrs.append(band_arr)\n",
    "        x_arr = np.stack(band_arrs, axis=-1) # 3-dimensional array\n",
    "\n",
    "        # Apply data augmentations, if provided\n",
    "        if self.transforms:\n",
    "            x_arr = self.transforms(image=x_arr)[\"image\"]\n",
    "        x_arr = np.transpose(x_arr, [2, 0, 1]) # re-orders array to match expected format needed for model\n",
    "\n",
    "        # Prepare dictionary for item\n",
    "        item = {\"chip_id\": img.chip_id, \"chip\": x_arr}\n",
    "\n",
    "        # Load label if available\n",
    "        if self.label is not None:\n",
    "            label_path = self.label.loc[idx].label_path\n",
    "            with rasterio.open(label_path) as lp:\n",
    "                y_arr = lp.read(1).astype(\"float32\")\n",
    "            # Apply same data augmentations to the label\n",
    "            if self.transforms:\n",
    "                y_arr = self.transforms(image=y_arr)[\"image\"]\n",
    "            item[\"label\"] = y_arr\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file {submission_dir}/cloud_model.py\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "from benchmark_src.cloud_dataset import CloudDataset\n",
    "\n",
    "try:\n",
    "    from cloud_dataset import CloudDataset\n",
    "    from losses import intersection_over_union\n",
    "except ImportError:\n",
    "    from benchmark_src.cloud_dataset import CloudDataset\n",
    "    from benchmark_src.losses import intersection_over_union\n",
    "\n",
    "class CloudModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bands: List[str],\n",
    "        x_train: Optional[pd.DataFrame] = None,\n",
    "        y_train: Optional[pd.DataFrame] = None,\n",
    "        x_val: Optional[pd.DataFrame] = None,\n",
    "        y_val: Optional[pd.DataFrame] = None,\n",
    "        hparams: dict = {},\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiate the CloudModel class based on the pl.LightningModule\n",
    "        (https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html).\n",
    "\n",
    "        Args:\n",
    "            bands (list[str]): Names of the bands provided for each chip\n",
    "            x_train (pd.DataFrame, optional): a dataframe of the training features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_train (pd.DataFrame, optional): a dataframe of the training labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            x_val (pd.DataFrame, optional): a dataframe of the validation features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_val (pd.DataFrame, optional): a dataframe of the validation labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            hparams (dict, optional): Dictionary of additional modeling parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hparams.update(hparams)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # required\n",
    "        self.bands = bands\n",
    "\n",
    "        # optional modeling params\n",
    "        self.backbone = self.hparams.get(\"backbone\", \"resnet34\")\n",
    "        self.weights = self.hparams.get(\"weights\", \"imagenet\")\n",
    "        self.learning_rate = self.hparams.get(\"lr\", 1e-3)\n",
    "        self.patience = self.hparams.get(\"patience\", 4)\n",
    "        self.num_workers = self.hparams.get(\"num_workers\", 2)\n",
    "        self.batch_size = self.hparams.get(\"batch_size\", 16)\n",
    "        self.gpu = self.hparams.get(\"gpu\", False)\n",
    "        self.transform = None\n",
    "\n",
    "        # Instantiate datasets, model, and trainer params if provided\n",
    "        self.train_dataset = CloudDataset(\n",
    "            x_paths=x_train,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_train,\n",
    "            transforms=self.transform,\n",
    "        )\n",
    "        self.val_dataset = CloudDataset(\n",
    "            x_paths=x_val,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_val,\n",
    "            transforms=None,\n",
    "        )\n",
    "        self.model = self._prepare_model()\n",
    "\n",
    "    ## Required LightningModule methods ##\n",
    "\n",
    "    def forward(self, image: torch.Tensor):\n",
    "        # Forward pass\n",
    "        return self.model(image)\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.train_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_train and y_train must be specified when CloudModel is instantiated to run training\"\n",
    "            )\n",
    "\n",
    "        # Switch on training mode\n",
    "        self.model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        # Log batch loss\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(preds, y).mean()\n",
    "        self.log(\n",
    "            \"loss\",\n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.val_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_val and y_val must be specified when CloudModel is instantiated to run validation\"\n",
    "            )\n",
    "\n",
    "        # Switch on validation mode\n",
    "        self.model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass & softmax\n",
    "        preds = self.forward(x)\n",
    "        preds = torch.softmax(preds, dim=1)[:, 1]\n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        # Log batch IOU\n",
    "        batch_iou = intersection_over_union(preds, y)\n",
    "        self.log(\n",
    "            \"iou\", batch_iou, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return batch_iou\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # DataLoader class for training\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # DataLoader class for validation\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
    "        return [opt], [sch]\n",
    "\n",
    "    ## Convenience Methods ##\n",
    "\n",
    "    def _prepare_model(self):\n",
    "        # Instantiate U-Net model\n",
    "        unet_model = smp.Unet(\n",
    "            encoder_name=self.backbone,\n",
    "            encoder_weights=self.weights,\n",
    "            in_channels=4,\n",
    "            classes=2,\n",
    "        )\n",
    "        if self.gpu:\n",
    "            unet_model.cuda()\n",
    "\n",
    "        return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cloud model we just saved.\n",
    "from benchmark_src.cloud_model import CloudModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Define functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paths(df, feature_dir, label_dir=None, bands=BANDS):\n",
    "    \"\"\"\n",
    "    Given dataframe with a column for chip_id, returns a dataframe with a column\n",
    "    added indicating the path to each band's TIF image as \"{band}_path\", eg \"B02_path\".\n",
    "    A column is also added to the dataframe with paths to the label TIF, if the\n",
    "    path to the labels directory is provided.\n",
    "    \"\"\"\n",
    "    for band in bands:\n",
    "        df[f\"{band}_path\"] = feature_dir / df[\"chip_id\"] / f\"{band}.tif\"\n",
    "        # make sure a random sample of paths exist\n",
    "        assert df.sample(n=40, random_state=5)[f\"{band}_path\"].path.exists().all()\n",
    "    if label_dir is not None:\n",
    "        df[\"label_path\"] = label_dir / (df[\"chip_id\"] + \".tif\")\n",
    "        # make sure a random sample of paths exist\n",
    "        assert df.sample(n=40, random_state=5)[\"label_path\"].path.exists().all()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Read data and preprocess\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = add_paths(train_meta, TRAIN_FEATURES, TRAIN_LABELS)\n",
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = train_val_test_split(train_meta, column='location', pct_train=0.6, pct_val=0.2, pct_test=0.2, random_state=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features from labels\n",
    "feature_cols = [\"chip_id\"] + [f\"{band}_path\" for band in BANDS]\n",
    "\n",
    "train_x = train[feature_cols].copy()\n",
    "train_y = train[[\"chip_id\", \"label_path\"]].copy()\n",
    "\n",
    "val_x = val[feature_cols].copy()\n",
    "val_y = val[[\"chip_id\", \"label_path\"]].copy()\n",
    "\n",
    "test_x = test[feature_cols].copy()\n",
    "test_y = test[[\"chip_id\", \"label_path\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up pytorch_lightning.Trainer object\n",
    "cloud_model = CloudModel(\n",
    "    bands=BANDS,\n",
    "    x_train=train_x,\n",
    "    y_train=train_y,\n",
    "    x_val=val_x,\n",
    "    y_val=val_y,\n",
    "    hparams={\"num_workers\": 7, \"batch_size\": 16},\n",
    ")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"iou_epoch\", mode=\"max\", verbose=True\n",
    ")\n",
    "early_stopping_callback = pl.callbacks.early_stopping.EarlyStopping(\n",
    "    monitor=\"iou_epoch\",\n",
    "    patience=(cloud_model.patience * 3),\n",
    "    mode=\"max\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    fast_dev_run=False,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    logger = wandb_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "trainer.fit(model = cloud_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "submission_assets_dir = submission_dir / \"assets\"\n",
    "submission_assets_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_weight_path = submission_assets_dir / \"cloud_model.pt\"\n",
    "torch.save(cloud_model.state_dict(), model_weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Model Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file benchmark_src/main.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import typer\n",
    "\n",
    "try:\n",
    "    from cloud_dataset import CloudDataset\n",
    "    from cloud_model import CloudModel\n",
    "except ImportError:\n",
    "    from benchmark_src.cloud_dataset import CloudDataset\n",
    "    from benchmark_src.cloud_model import CloudModel\n",
    "\n",
    "\n",
    "ROOT_DIRECTORY = Path(\"/codeexecution\")\n",
    "PREDICTIONS_DIRECTORY = ROOT_DIRECTORY / \"predictions\"\n",
    "ASSETS_DIRECTORY = ROOT_DIRECTORY / \"assets\"\n",
    "DATA_DIRECTORY = ROOT_DIRECTORY / \"data\"\n",
    "INPUT_IMAGES_DIRECTORY = DATA_DIRECTORY / \"test_features\"\n",
    "\n",
    "# Set the pytorch cache directory and include cached models in your submission.zip\n",
    "os.environ[\"TORCH_HOME\"] = str(ASSETS_DIRECTORY / \"assets/torch\")\n",
    "\n",
    "\n",
    "def get_metadata(features_dir: os.PathLike, bands: List[str]):\n",
    "    \"\"\"\n",
    "    Given a folder of feature data, return a dataframe where the index is the chip id\n",
    "    and there is a column for the path to each band's TIF image.\n",
    "\n",
    "    Args:\n",
    "        features_dir (os.PathLike): path to the directory of feature data, which should have\n",
    "            a folder for each chip\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "    \"\"\"\n",
    "    chip_metadata = pd.DataFrame(index=[f\"{band}_path\" for band in bands])\n",
    "    chip_ids = (\n",
    "        pth.name for pth in features_dir.iterdir() if not pth.name.startswith(\".\")\n",
    "    )\n",
    "\n",
    "    for chip_id in chip_ids:\n",
    "        chip_bands = [features_dir / chip_id / f\"{band}.tif\" for band in bands]\n",
    "        chip_metadata[chip_id] = chip_bands\n",
    "\n",
    "    return chip_metadata.transpose().reset_index().rename(columns={\"index\": \"chip_id\"})\n",
    "\n",
    "\n",
    "def make_predictions(\n",
    "    model: CloudModel,\n",
    "    x_paths: pd.DataFrame,\n",
    "    bands: List[str],\n",
    "    predictions_dir: os.PathLike,\n",
    "):\n",
    "    \"\"\"Predicts cloud cover and saves results to the predictions directory.\n",
    "\n",
    "    Args:\n",
    "        model (CloudModel): an instantiated CloudModel based on pl.LightningModule\n",
    "        x_paths (pd.DataFrame): a dataframe with a row for each chip. There must be a column for chip_id,\n",
    "                and a column with the path to the TIF for each of bands provided\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "        predictions_dir (os.PathLike): Destination directory to save the predicted TIF masks\n",
    "    \"\"\"\n",
    "    test_dataset = CloudDataset(x_paths=x_paths, bands=bands)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=model.batch_size,\n",
    "        num_workers=model.num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    for batch_index, batch in enumerate(test_dataloader):\n",
    "        logger.debug(f\"Predicting batch {batch_index} of {len(test_dataloader)}\")\n",
    "        x = batch[\"chip\"]\n",
    "        preds = model.forward(x)\n",
    "        preds = torch.softmax(preds, dim=1)[:, 1]\n",
    "        preds = (preds > 0.5).detach().numpy().astype(\"uint8\")\n",
    "        for chip_id, pred in zip(batch[\"chip_id\"], preds):\n",
    "            chip_pred_path = predictions_dir / f\"{chip_id}.tif\"\n",
    "            chip_pred_im = Image.fromarray(pred)\n",
    "            chip_pred_im.save(chip_pred_path)\n",
    "\n",
    "\n",
    "def main(\n",
    "    model_weights_path: Path = ASSETS_DIRECTORY / \"cloud_model.pt\",\n",
    "    test_features_dir: Path = DATA_DIRECTORY / \"test_features\",\n",
    "    predictions_dir: Path = PREDICTIONS_DIRECTORY,\n",
    "    bands: List[str] = [\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "    fast_dev_run: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate predictions for the chips in test_features_dir using the model saved at\n",
    "    model_weights_path.\n",
    "\n",
    "    Predictions are saved in predictions_dir. The default paths to all three files are based on\n",
    "    the structure of the code execution runtime.\n",
    "\n",
    "    Args:\n",
    "        model_weights_path (os.PathLike): Path to the weights of a trained CloudModel.\n",
    "        test_features_dir (os.PathLike, optional): Path to the features for the test data. Defaults\n",
    "            to 'data/test_features' in the same directory as main.py\n",
    "        predictions_dir (os.PathLike, optional): Destination directory to save the predicted TIF masks\n",
    "            Defaults to 'predictions' in the same directory as main.py\n",
    "        bands (List[str], optional): List of bands provided for each chip\n",
    "    \"\"\"\n",
    "    if not test_features_dir.exists():\n",
    "        raise ValueError(\n",
    "            f\"The directory for test feature images must exist and {test_features_dir} does not exist\"\n",
    "        )\n",
    "    predictions_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    logger.info(\"Loading model\")\n",
    "    model = CloudModel(bands=bands, hparams={\"weights\": None})\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "\n",
    "    logger.info(\"Loading test metadata\")\n",
    "    test_metadata = get_metadata(test_features_dir, bands=bands)\n",
    "    if fast_dev_run:\n",
    "        test_metadata = test_metadata.head()\n",
    "    logger.info(f\"Found {len(test_metadata)} chips\")\n",
    "\n",
    "    logger.info(\"Generating predictions in batches\")\n",
    "    make_predictions(model, test_metadata, bands, predictions_dir)\n",
    "\n",
    "    logger.info(f\"\"\"Saved {len(list(predictions_dir.glob(\"*.tif\")))} predictions\"\"\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    typer.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_src.main import main\n",
    "\n",
    "main(\n",
    "    model_weights_path=submission_dir / \"assets/cloud_model.pt\",\n",
    "    test_features_dir=TRAIN_FEATURES,\n",
    "    predictions_dir=submission_dir / \"predictions\",\n",
    "    fast_dev_run=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
